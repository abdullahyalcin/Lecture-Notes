### Q1. What is the Central Limit Theorem and why is it important?

if we sample from a population using a sufficiently large sample size, the mean of the samples (also known as the sample
population) will be normally distributed (assuming true random sampling), the mean tending to the mean
of the population and variance equal to the variance of the population divided by the size of the sampling.
What’s especially important is that this will be true regardless of the distribution of the original
population.


### Q2. What is sampling? How many sampling methods do you know? 

Data sampling is a statistical analysis technique used to select, manipulate and analyze a representative
subset of data points to identify patterns and trends in the larger data set being examined.

There are many different methods for drawing samples from data; the ideal one depends on the data set
and situation. Sampling can be based on *probability*, an approach that uses random numbers that
correspond to points in the data set to ensure that there is no correlation between points chosen for the
sample. Further variations in probability sampling include:
• Simple random sampling:
• Stratified sampling: 
• Cluster sampling: 
• Multistage sampling:
• Systematic sampling:

Sampling can also be based on *non-probability*, an approach in which a data sample is determined and
extracted based on the judgment of the analyst.
• Convenience sampling: 
• Consecutive sampling: 
• Purposive or judgmental sampling:
• Quota sampling: 
